{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:31.207334Z",
     "iopub.status.busy": "2025-09-09T19:40:31.206803Z",
     "iopub.status.idle": "2025-09-09T19:40:31.489252Z",
     "shell.execute_reply": "2025-09-09T19:40:31.488491Z",
     "shell.execute_reply.started": "2025-09-09T19:40:31.207310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:31.490843Z",
     "iopub.status.busy": "2025-09-09T19:40:31.490494Z",
     "iopub.status.idle": "2025-09-09T19:40:31.543232Z",
     "shell.execute_reply": "2025-09-09T19:40:31.542560Z",
     "shell.execute_reply.started": "2025-09-09T19:40:31.490826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "complaints = pd.read_csv(\"/kaggle/input/complaints/complaints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:31.544390Z",
     "iopub.status.busy": "2025-09-09T19:40:31.544041Z",
     "iopub.status.idle": "2025-09-09T19:40:31.579219Z",
     "shell.execute_reply": "2025-09-09T19:40:31.578554Z",
     "shell.execute_reply.started": "2025-09-09T19:40:31.544371Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5788 entries, 0 to 5787\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Ticket_ID       5788 non-null   object \n",
      " 1   Student_ID      5788 non-null   object \n",
      " 2   Category        5788 non-null   object \n",
      " 3   Complaint_Text  5788 non-null   object \n",
      " 4   Priority        5787 non-null   object \n",
      " 5   Status          5787 non-null   object \n",
      " 6   Date_Submitted  5771 non-null   object \n",
      " 7   Unnamed: 0.1    3286 non-null   float64\n",
      " 8   Unnamed: 0      991 non-null    float64\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 407.1+ KB\n"
     ]
    }
   ],
   "source": [
    "complaints.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:31.582604Z",
     "iopub.status.busy": "2025-09-09T19:40:31.582383Z",
     "iopub.status.idle": "2025-09-09T19:40:31.653102Z",
     "shell.execute_reply": "2025-09-09T19:40:31.652347Z",
     "shell.execute_reply.started": "2025-09-09T19:40:31.582585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket_ID</th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complaint_Text</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Date_Submitted</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5788</td>\n",
       "      <td>5788</td>\n",
       "      <td>5788</td>\n",
       "      <td>5788</td>\n",
       "      <td>5787</td>\n",
       "      <td>5787</td>\n",
       "      <td>5771</td>\n",
       "      <td>3286.000000</td>\n",
       "      <td>991.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1300</td>\n",
       "      <td>2778</td>\n",
       "      <td>4</td>\n",
       "      <td>5788</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TCKT0090</td>\n",
       "      <td>S11234</td>\n",
       "      <td>Academic Support and Resources</td>\n",
       "      <td>Dear Team, My university email rejects attachm...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Open</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1483</td>\n",
       "      <td>1</td>\n",
       "      <td>2892</td>\n",
       "      <td>3469</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1642.500000</td>\n",
       "      <td>514.889001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>948.730819</td>\n",
       "      <td>294.264098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>821.250000</td>\n",
       "      <td>272.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1642.500000</td>\n",
       "      <td>520.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2463.750000</td>\n",
       "      <td>767.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3285.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ticket_ID Student_ID                        Category  \\\n",
       "count       5788       5788                            5788   \n",
       "unique      1300       2778                               4   \n",
       "top     TCKT0090     S11234  Academic Support and Resources   \n",
       "freq          10         15                            1483   \n",
       "mean         NaN        NaN                             NaN   \n",
       "std          NaN        NaN                             NaN   \n",
       "min          NaN        NaN                             NaN   \n",
       "25%          NaN        NaN                             NaN   \n",
       "50%          NaN        NaN                             NaN   \n",
       "75%          NaN        NaN                             NaN   \n",
       "max          NaN        NaN                             NaN   \n",
       "\n",
       "                                           Complaint_Text Priority Status  \\\n",
       "count                                                5788     5787   5787   \n",
       "unique                                               5788        7     19   \n",
       "top     Dear Team, My university email rejects attachm...   Medium   Open   \n",
       "freq                                                    1     2892   3469   \n",
       "mean                                                  NaN      NaN    NaN   \n",
       "std                                                   NaN      NaN    NaN   \n",
       "min                                                   NaN      NaN    NaN   \n",
       "25%                                                   NaN      NaN    NaN   \n",
       "50%                                                   NaN      NaN    NaN   \n",
       "75%                                                   NaN      NaN    NaN   \n",
       "max                                                   NaN      NaN    NaN   \n",
       "\n",
       "       Date_Submitted  Unnamed: 0.1   Unnamed: 0  \n",
       "count            5771   3286.000000   991.000000  \n",
       "unique            820           NaN          NaN  \n",
       "top        2025-08-31           NaN          NaN  \n",
       "freq               72           NaN          NaN  \n",
       "mean              NaN   1642.500000   514.889001  \n",
       "std               NaN    948.730819   294.264098  \n",
       "min               NaN      0.000000     0.000000  \n",
       "25%               NaN    821.250000   272.500000  \n",
       "50%               NaN   1642.500000   520.000000  \n",
       "75%               NaN   2463.750000   767.500000  \n",
       "max               NaN   3285.000000  1024.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:31.654150Z",
     "iopub.status.busy": "2025-09-09T19:40:31.653925Z",
     "iopub.status.idle": "2025-09-09T19:40:31.657845Z",
     "shell.execute_reply": "2025-09-09T19:40:31.657119Z",
     "shell.execute_reply.started": "2025-09-09T19:40:31.654123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "complaints=complaints[[\"Complaint_Text\",\"Category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:31.658780Z",
     "iopub.status.busy": "2025-09-09T19:40:31.658606Z",
     "iopub.status.idle": "2025-09-09T19:40:31.672143Z",
     "shell.execute_reply": "2025-09-09T19:40:31.671607Z",
     "shell.execute_reply.started": "2025-09-09T19:40:31.658759Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Complaint_Text', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:31.672773Z",
     "iopub.status.busy": "2025-09-09T19:40:31.672619Z",
     "iopub.status.idle": "2025-09-09T19:40:35.316097Z",
     "shell.execute_reply": "2025-09-09T19:40:35.315561Z",
     "shell.execute_reply.started": "2025-09-09T19:40:31.672760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:35.317094Z",
     "iopub.status.busy": "2025-09-09T19:40:35.316819Z",
     "iopub.status.idle": "2025-09-09T19:40:39.200688Z",
     "shell.execute_reply": "2025-09-09T19:40:39.199799Z",
     "shell.execute_reply.started": "2025-09-09T19:40:35.317077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making label encoder on category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:39.202076Z",
     "iopub.status.busy": "2025-09-09T19:40:39.201794Z",
     "iopub.status.idle": "2025-09-09T19:40:39.738994Z",
     "shell.execute_reply": "2025-09-09T19:40:39.738422Z",
     "shell.execute_reply.started": "2025-09-09T19:40:39.202052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "complaints[\"Category\"] = encoder.fit_transform(complaints[\"Category\"])\n",
    "sentences = complaints.Complaint_Text.values\n",
    "labels = complaints.Category.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:39.742091Z",
     "iopub.status.busy": "2025-09-09T19:40:39.741588Z",
     "iopub.status.idle": "2025-09-09T19:40:39.747147Z",
     "shell.execute_reply": "2025-09-09T19:40:39.746450Z",
     "shell.execute_reply.started": "2025-09-09T19:40:39.742073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# having tokenizer of bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:39.747978Z",
     "iopub.status.busy": "2025-09-09T19:40:39.747794Z",
     "iopub.status.idle": "2025-09-09T19:40:44.844955Z",
     "shell.execute_reply": "2025-09-09T19:40:44.844366Z",
     "shell.execute_reply.started": "2025-09-09T19:40:39.747959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befb909b0ed7478d97bfde06047c8fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b221f2c9324db688dc0543b5ec5309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cae71bcc3e4f3eb32758db6dfbe63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f63c9181d1243f9bbf14dc20f49b58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:44.846278Z",
     "iopub.status.busy": "2025-09-09T19:40:44.845805Z",
     "iopub.status.idle": "2025-09-09T19:40:46.534088Z",
     "shell.execute_reply": "2025-09-09T19:40:46.533464Z",
     "shell.execute_reply.started": "2025-09-09T19:40:44.846255Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  62\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:46.535035Z",
     "iopub.status.busy": "2025-09-09T19:40:46.534821Z",
     "iopub.status.idle": "2025-09-09T19:40:48.874078Z",
     "shell.execute_reply": "2025-09-09T19:40:48.873316Z",
     "shell.execute_reply.started": "2025-09-09T19:40:46.535019Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  المصاريف دي عاملاني مشاكل كبيرة، والردود مش موجودة أبداً.\n",
      "Token IDs: tensor([  101, 24177, 10720, 36139, 19455, 35476, 59673, 23860,   476, 80958,\n",
      "        34003,   446,   479, 13259, 91296, 10727,   476, 11691, 29606, 10400,\n",
      "        19767, 14363,   119,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,            # Pad & truncate all sentences\n",
    "                        padding = 'max_length',     # <-- بدل pad_to_max_length\n",
    "                        truncation = True,          # لازم تحطها علشان يقطع لو أطول\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making dataset divided into train valiation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:48.875141Z",
     "iopub.status.busy": "2025-09-09T19:40:48.874834Z",
     "iopub.status.idle": "2025-09-09T19:40:48.884805Z",
     "shell.execute_reply": "2025-09-09T19:40:48.884236Z",
     "shell.execute_reply.started": "2025-09-09T19:40:48.875124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,051 training samples\n",
      "1,157 validation samples\n",
      "580 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Calculate sizes\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.2 * total_size)\n",
    "test_size = total_size - train_size - val_size  # ensures all samples are used\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"{train_size:,} training samples\")\n",
    "print(f\"{val_size:,} validation samples\")\n",
    "print(f\"{test_size:,} test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:48.885748Z",
     "iopub.status.busy": "2025-09-09T19:40:48.885442Z",
     "iopub.status.idle": "2025-09-09T19:40:48.898413Z",
     "shell.execute_reply": "2025-09-09T19:40:48.897756Z",
     "shell.execute_reply.started": "2025-09-09T19:40:48.885721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the pretrained classifier Bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:40:48.899315Z",
     "iopub.status.busy": "2025-09-09T19:40:48.899098Z",
     "iopub.status.idle": "2025-09-09T19:41:08.861976Z",
     "shell.execute_reply": "2025-09-09T19:41:08.861339Z",
     "shell.execute_reply.started": "2025-09-09T19:40:48.899300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 19:40:54.311931: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757446854.496587      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757446854.561035      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d1224e942d40aa8166b05db7ab350b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "\n",
    "# Load multilingual uncased BERT for classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-uncased\",\n",
    "    num_labels=4,              # adjust to your dataset (4 classes here)\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "# Move model to GPU (if available)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:41:08.863200Z",
     "iopub.status.busy": "2025-09-09T19:41:08.862660Z",
     "iopub.status.idle": "2025-09-09T19:41:08.867871Z",
     "shell.execute_reply": "2025-09-09T19:41:08.867138Z",
     "shell.execute_reply.started": "2025-09-09T19:41:08.863180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:41:08.868918Z",
     "iopub.status.busy": "2025-09-09T19:41:08.868637Z",
     "iopub.status.idle": "2025-09-09T19:41:08.939936Z",
     "shell.execute_reply": "2025-09-09T19:41:08.939237Z",
     "shell.execute_reply.started": "2025-09-09T19:41:08.868894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:41:08.940924Z",
     "iopub.status.busy": "2025-09-09T19:41:08.940677Z",
     "iopub.status.idle": "2025-09-09T19:41:13.031998Z",
     "shell.execute_reply": "2025-09-09T19:41:13.031039Z",
     "shell.execute_reply.started": "2025-09-09T19:41:08.940907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:41:13.033897Z",
     "iopub.status.busy": "2025-09-09T19:41:13.033257Z",
     "iopub.status.idle": "2025-09-09T19:41:13.039203Z",
     "shell.execute_reply": "2025-09-09T19:41:13.038495Z",
     "shell.execute_reply.started": "2025-09-09T19:41:13.033870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:41:13.040828Z",
     "iopub.status.busy": "2025-09-09T19:41:13.040112Z",
     "iopub.status.idle": "2025-09-09T19:41:13.055089Z",
     "shell.execute_reply": "2025-09-09T19:41:13.054312Z",
     "shell.execute_reply.started": "2025-09-09T19:41:13.040800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:41:13.055934Z",
     "iopub.status.busy": "2025-09-09T19:41:13.055721Z",
     "iopub.status.idle": "2025-09-09T19:41:13.070753Z",
     "shell.execute_reply": "2025-09-09T19:41:13.070140Z",
     "shell.execute_reply.started": "2025-09-09T19:41:13.055919Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Academic Support and Resources',\n",
       " 1: 'Financial Support',\n",
       " 2: 'IT',\n",
       " 3: 'Student Affairs'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = dict(enumerate(encoder.classes_))\n",
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:41:13.071704Z",
     "iopub.status.busy": "2025-09-09T19:41:13.071467Z",
     "iopub.status.idle": "2025-09-09T19:41:13.084370Z",
     "shell.execute_reply": "2025-09-09T19:41:13.083704Z",
     "shell.execute_reply.started": "2025-09-09T19:41:13.071690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def f1_score_from_scratch(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute F1 score (macro average) from scratch.\n",
    "    \"\"\"\n",
    "    classes = np.unique(y_true)\n",
    "    f1_scores = []\n",
    "    for cls in classes:\n",
    "        tp = np.sum((y_pred == cls) & (y_true == cls))\n",
    "        fp = np.sum((y_pred == cls) & (y_true != cls))\n",
    "        fn = np.sum((y_pred != cls) & (y_true == cls))\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return np.mean(f1_scores)  # macro average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the classifier on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:41:13.085312Z",
     "iopub.status.busy": "2025-09-09T19:41:13.085122Z",
     "iopub.status.idle": "2025-09-09T19:42:57.920394Z",
     "shell.execute_reply": "2025-09-09T19:42:57.919717Z",
     "shell.execute_reply.started": "2025-09-09T19:41:13.085298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    127.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    127.    Elapsed: 0:00:17.\n",
      "  Batch   120  of    127.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training Accuracy: 0.73\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    127.    Elapsed: 0:00:08.\n",
      "  Batch    80  of    127.    Elapsed: 0:00:16.\n",
      "  Batch   120  of    127.    Elapsed: 0:00:24.\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training Accuracy: 0.94\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    127.    Elapsed: 0:00:08.\n",
      "  Batch    80  of    127.    Elapsed: 0:00:16.\n",
      "  Batch   120  of    127.    Elapsed: 0:00:24.\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training Accuracy: 0.97\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    127.    Elapsed: 0:00:08.\n",
      "  Batch    80  of    127.    Elapsed: 0:00:16.\n",
      "  Batch   120  of    127.    Elapsed: 0:00:24.\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training Accuracy: 0.98\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation Accuracy: 0.96\n",
      "  Validation Loss: 0.15\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "Academic Support and Resources       0.96      0.93      0.95       292\n",
      "             Financial Support       0.99      0.98      0.99       298\n",
      "                            IT       0.93      0.97      0.95       289\n",
      "               Student Affairs       0.97      0.97      0.97       278\n",
      "\n",
      "                      accuracy                           0.96      1157\n",
      "                     macro avg       0.96      0.96      0.96      1157\n",
      "                  weighted avg       0.96      0.96      0.96      1157\n",
      "\n",
      "Confusion Matrix:\n",
      "[[273   1  15   3]\n",
      " [  1 293   2   2]\n",
      " [  6   0 280   3]\n",
      " [  4   2   3 269]]\n",
      "F1 Score (macro): 0.9636\n",
      "F1 Score (micro): 0.9637\n",
      "F1 Score (weighted): 0.9637\n",
      "F1 Score (macro, from scratch): 0.9636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Measure total training time\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    total_train_accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask, \n",
    "            labels=b_labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Training accuracy\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)  \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training Accuracy: {0:.2f}\".format(avg_train_accuracy))  \n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ===== Validation =====\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# ===== Validation =====\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "\n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask, \n",
    "            labels=b_labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "            \n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "    labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "    total_eval_accuracy += np.sum(preds == labels) / len(labels)\n",
    "\n",
    "avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "validation_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"  Validation Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "# === NEW: Classification Report + Confusion Matrix + F1 ===\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=list(id2label.values())))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "# F1 with sklearn\n",
    "print(\"F1 Score (macro): {:.4f}\".format(f1_score(all_labels, all_preds, average='macro')))\n",
    "print(\"F1 Score (micro): {:.4f}\".format(f1_score(all_labels, all_preds, average='micro')))\n",
    "print(\"F1 Score (weighted): {:.4f}\".format(f1_score(all_labels, all_preds, average='weighted')))\n",
    "\n",
    "# F1 from scratch\n",
    "print(\"F1 Score (macro, from scratch): {:.4f}\".format(f1_score_from_scratch(np.array(all_labels), np.array(all_preds))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict function to test data on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:42:57.921391Z",
     "iopub.status.busy": "2025-09-09T19:42:57.921201Z",
     "iopub.status.idle": "2025-09-09T19:42:58.413782Z",
     "shell.execute_reply": "2025-09-09T19:42:58.413192Z",
     "shell.execute_reply.started": "2025-09-09T19:42:57.921377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load the same tokenizer used for training (multilingual)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "def predict_sentence(sentence, model, device):\n",
    "    # Tokenize the input (works with Arabic, English, etc.)\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sentence,                      \n",
    "        add_special_tokens=True,       # [CLS] and [SEP]\n",
    "        max_length=64,                 # Pad & truncate\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,    \n",
    "        return_tensors='pt',           \n",
    "    )\n",
    "    \n",
    "    # Move tensors to device\n",
    "    input_ids = encoded_dict['input_ids'].to(device)\n",
    "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
    "    \n",
    "    # Eval mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Convert logits to prediction\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probs, dim=1).cpu().item()\n",
    "    \n",
    "    return predicted_class, probs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Testing loop on test data before predicting on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:42:58.414803Z",
     "iopub.status.busy": "2025-09-09T19:42:58.414549Z",
     "iopub.status.idle": "2025-09-09T19:42:59.388884Z",
     "shell.execute_reply": "2025-09-09T19:42:59.388099Z",
     "shell.execute_reply.started": "2025-09-09T19:42:58.414777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test Evaluation...\n",
      "  Test Accuracy: 0.96\n",
      "  Test Loss: 0.15\n",
      "\n",
      "Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "Academic Support and Resources       0.95      0.93      0.94       148\n",
      "             Financial Support       0.97      0.98      0.98       150\n",
      "                            IT       0.94      0.98      0.96       135\n",
      "               Student Affairs       0.99      0.96      0.97       147\n",
      "\n",
      "                      accuracy                           0.96       580\n",
      "                     macro avg       0.96      0.96      0.96       580\n",
      "                  weighted avg       0.96      0.96      0.96       580\n",
      "\n",
      "Confusion Matrix:\n",
      "[[138   3   7   0]\n",
      " [  2 147   0   1]\n",
      " [  2   0 132   1]\n",
      " [  3   1   2 141]]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# For testing we don’t need shuffling (use SequentialSampler)\n",
    "batch_size = 32  # adjust depending on GPU memory\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,  # <-- the dataset you got from random_split\n",
    "    sampler=SequentialSampler(test_dataset),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Test Evaluation...\")\n",
    "\n",
    "model.eval()\n",
    "total_test_accuracy = 0\n",
    "total_test_loss = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "    total_test_loss += loss.item()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Accuracy\n",
    "    total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Predictions\n",
    "    preds = np.argmax(logits, axis=1).flatten()\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(label_ids)\n",
    "\n",
    "avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
    "avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "\n",
    "print(\"  Test Accuracy: {0:.2f}\".format(avg_test_accuracy))\n",
    "print(\"  Test Loss: {0:.2f}\".format(avg_test_loss))\n",
    "\n",
    "# ---- Extra evaluation ----\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=encoder.classes_))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting on totally new data made by chatgpt different from the one from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:42:59.389917Z",
     "iopub.status.busy": "2025-09-09T19:42:59.389721Z",
     "iopub.status.idle": "2025-09-09T19:42:59.965365Z",
     "shell.execute_reply": "2025-09-09T19:42:59.964650Z",
     "shell.execute_reply.started": "2025-09-09T19:42:59.389893Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I need help understanding the course material.\n",
      "Predicted Category: Academic Support\n",
      "\n",
      "Sentence: My scholarship payment has not arrived yet.\n",
      "Predicted Category: Financial Support\n",
      "\n",
      "Sentence: The university Wi-Fi is not working.\n",
      "Predicted Category: IT\n",
      "\n",
      "Sentence: I want to apply for a student club.\n",
      "Predicted Category: Student Affairs\n",
      "\n",
      "Sentence: أحتاج إلى مساعدة في فهم محاضراتي.\n",
      "Predicted Category: Academic Support\n",
      "\n",
      "Sentence: لم أتسلم المنحة المالية حتى الآن.\n",
      "Predicted Category: Financial Support\n",
      "\n",
      "Sentence: الإنترنت في الجامعة بطيء جدًا.\n",
      "Predicted Category: IT\n",
      "\n",
      "Sentence: أرغب في التسجيل في نشاط طلابي.\n",
      "Predicted Category: IT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the same multilingual tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "# Define your label mapping (order must match your training)\n",
    "categories = [\"Academic Support\", \"Financial Support\", \"IT\", \"Student Affairs\"]\n",
    "\n",
    "def predict_sentence(sentence, model, device):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sentence,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_dict['input_ids'].to(device)\n",
    "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probs, dim=1).cpu().item()\n",
    "\n",
    "    return categories[predicted_class], probs.cpu().numpy()\n",
    "\n",
    "# Example test sentences (Arabic + English)\n",
    "test_sentences = [\n",
    "    \"I need help understanding the course material.\",\n",
    "    \"My scholarship payment has not arrived yet.\",\n",
    "    \"The university Wi-Fi is not working.\",\n",
    "    \"I want to apply for a student club.\",\n",
    "    \"أحتاج إلى مساعدة في فهم محاضراتي.\",\n",
    "    \"لم أتسلم المنحة المالية حتى الآن.\",\n",
    "    \"الإنترنت في الجامعة بطيء جدًا.\",\n",
    "    \"أرغب في التسجيل في نشاط طلابي.\"\n",
    "]\n",
    "\n",
    "# Run predictions\n",
    "for s in test_sentences:\n",
    "    pred_class, probs = predict_sentence(s, model, device)\n",
    "    print(f\"Sentence: {s}\")\n",
    "    print(f\"Predicted Category: {pred_class}\\n\")\n",
    "# Sentence: I need help understanding the course material.\n",
    "# Predicted Category: Academic Support\n",
    "\n",
    "# Sentence: My scholarship payment has not arrived yet.\n",
    "# Predicted Category: Financial Support\n",
    "\n",
    "# Sentence: The university Wi-Fi is not working.\n",
    "# Predicted Category: IT\n",
    "\n",
    "# Sentence: I want to apply for a student club.\n",
    "# Predicted Category: Student Affairs\n",
    "\n",
    "# Sentence: أحتاج إلى مساعدة في فهم محاضراتي.\n",
    "# Predicted Category: Academic Support\n",
    "\n",
    "# Sentence: لم أتسلم المنحة المالية حتى الآن.\n",
    "# Predicted Category: Financial Support\n",
    "\n",
    "# Sentence: الإنترنت في الجامعة بطيء جدًا.\n",
    "# Predicted Category: IT\n",
    "\n",
    "# Sentence: أرغب في التسجيل في نشاط طلابي.\n",
    "# Predicted Category: Student Affairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:42:59.969263Z",
     "iopub.status.busy": "2025-09-09T19:42:59.969049Z",
     "iopub.status.idle": "2025-09-09T19:42:59.973126Z",
     "shell.execute_reply": "2025-09-09T19:42:59.972359Z",
     "shell.execute_reply.started": "2025-09-09T19:42:59.969247Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Academic Support and Resources' 'Financial Support' 'IT'\n",
      " 'Student Affairs']\n",
      "{0: 'Academic Support and Resources', 1: 'Financial Support', 2: 'IT', 3: 'Student Affairs'}\n"
     ]
    }
   ],
   "source": [
    "print(encoder.classes_)\n",
    "id2label = dict(enumerate(encoder.classes_))\n",
    "print(id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:42:59.974086Z",
     "iopub.status.busy": "2025-09-09T19:42:59.973867Z",
     "iopub.status.idle": "2025-09-09T19:42:59.990203Z",
     "shell.execute_reply": "2025-09-09T19:42:59.989533Z",
     "shell.execute_reply.started": "2025-09-09T19:42:59.974061Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'المصاريف دي عاملاني مشاكل كبيرة، والردود مش موجودة أبداً.': 'Financial Support',\n",
       " 'السكن الجامعي غير ملائم بتاتاً، والنظافة في أسوأ حال.': 'Student Affairs',\n",
       " 'أحتاج تفاصيل أكثر عن طريقة استخدام المختبر لأني محتار.': 'Academic Support and Resources',\n",
       " 'خدمة الإنترنت في المكتبة غير ثابتة، وهذا يعيق تحضير الأبحاث.': 'IT',\n",
       " 'تتغير الفواتير دون إبلاغ، وهذا غير مقبول ويجب تصحيحه فوراً.': 'Financial Support'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ = ['Financial Support',  'Student Affairs',  'Academic Support and Resources',  'IT',  'Financial Support']\n",
    "complaint = ['المصاريف دي عاملاني مشاكل كبيرة، والردود مش موجودة أبداً.',  'السكن الجامعي غير ملائم بتاتاً، والنظافة في أسوأ حال.', 'أحتاج تفاصيل أكثر عن طريقة استخدام المختبر لأني محتار.', 'خدمة الإنترنت في المكتبة غير ثابتة، وهذا يعيق تحضير الأبحاث.',  'تتغير الفواتير دون إبلاغ، وهذا غير مقبول ويجب تصحيحه فوراً.']\n",
    "test={}\n",
    "for i in range (len(categ)):\n",
    "    test[complaint[i]]=categ[i]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:42:59.991132Z",
     "iopub.status.busy": "2025-09-09T19:42:59.990935Z",
     "iopub.status.idle": "2025-09-09T19:43:00.049624Z",
     "shell.execute_reply": "2025-09-09T19:43:00.049045Z",
     "shell.execute_reply.started": "2025-09-09T19:42:59.991110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: المصاريف دي عاملاني مشاكل كبيرة، والردود مش موجودة أبداً.\n",
      "Predicted Category: Financial Support\n",
      "\n",
      "Sentence: السكن الجامعي غير ملائم بتاتاً، والنظافة في أسوأ حال.\n",
      "Predicted Category: Student Affairs\n",
      "\n",
      "Sentence: أحتاج تفاصيل أكثر عن طريقة استخدام المختبر لأني محتار.\n",
      "Predicted Category: Academic Support\n",
      "\n",
      "Sentence: خدمة الإنترنت في المكتبة غير ثابتة، وهذا يعيق تحضير الأبحاث.\n",
      "Predicted Category: IT\n",
      "\n",
      "Sentence: تتغير الفواتير دون إبلاغ، وهذا غير مقبول ويجب تصحيحه فوراً.\n",
      "Predicted Category: Financial Support\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in test.keys():\n",
    "    pred_class, probs = predict_sentence(s, model, device)\n",
    "    print(f\"Sentence: {s}\")\n",
    "    print(f\"Predicted Category: {pred_class}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:43:00.050918Z",
     "iopub.status.busy": "2025-09-09T19:43:00.050340Z",
     "iopub.status.idle": "2025-09-09T19:43:00.056242Z",
     "shell.execute_reply": "2025-09-09T19:43:00.055572Z",
     "shell.execute_reply.started": "2025-09-09T19:43:00.050896Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'المحاضرات غير منظمة وتحتاج ترتيب.': 'Academic Support and Resources',\n",
       " 'المساعدات لا تصل للطلاب المحتاجين.': 'Financial Support',\n",
       " 'الواجهة الإلكترونية للجامعة مش واضحة ومحبطة': 'Academic Support and Resources',\n",
       " 'سكن الطلاب عامل زي ملعب مصارعة مصري، دايمًا فيه مصارعين جدد': 'Student Affairs',\n",
       " 'عدم انتظام مواعيد النقل يسبب مشكلات كبيرة للطلاب': 'Student Affairs'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaint = ['المحاضرات غير منظمة وتحتاج ترتيب.', 'المساعدات لا تصل للطلاب المحتاجين.',  'الواجهة الإلكترونية للجامعة مش واضحة ومحبطة', 'سكن الطلاب عامل زي ملعب مصارعة مصري، دايمًا فيه مصارعين جدد',  'عدم انتظام مواعيد النقل يسبب مشكلات كبيرة للطلاب']\n",
    "categ = [ 'Academic Support and Resources', 'Financial Support', 'Academic Support and Resources', 'Student Affairs','Student Affairs']\n",
    "test={}\n",
    "for i in range (len(categ)):\n",
    "    test[complaint[i]]=categ[i]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:43:00.057207Z",
     "iopub.status.busy": "2025-09-09T19:43:00.056987Z",
     "iopub.status.idle": "2025-09-09T19:43:00.118205Z",
     "shell.execute_reply": "2025-09-09T19:43:00.117553Z",
     "shell.execute_reply.started": "2025-09-09T19:43:00.057184Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: المحاضرات غير منظمة وتحتاج ترتيب.\n",
      "Predicted Category: Academic Support\n",
      "\n",
      "Sentence: المساعدات لا تصل للطلاب المحتاجين.\n",
      "Predicted Category: Financial Support\n",
      "\n",
      "Sentence: الواجهة الإلكترونية للجامعة مش واضحة ومحبطة\n",
      "Predicted Category: Academic Support\n",
      "\n",
      "Sentence: سكن الطلاب عامل زي ملعب مصارعة مصري، دايمًا فيه مصارعين جدد\n",
      "Predicted Category: Student Affairs\n",
      "\n",
      "Sentence: عدم انتظام مواعيد النقل يسبب مشكلات كبيرة للطلاب\n",
      "Predicted Category: Student Affairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in test.keys():\n",
    "    pred_class, probs = predict_sentence(s, model, device)\n",
    "    print(f\"Sentence: {s}\")\n",
    "    print(f\"Predicted Category: {pred_class}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8228405,
     "sourceId": 12999045,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8229768,
     "sourceId": 13000608,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8229794,
     "sourceId": 13000647,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
